# ------------------------------------------------------------
# ğŸ“˜ Documentation du Projet GA4 Checker
# ------------------------------------------------------------

## ğŸ¯ Objectif du Projet
L'objectif de ce projet est de mettre en place une sÃ©rie de **contrÃ´les automatisÃ©s** permettant de vÃ©rifier la **qualitÃ© des donnÃ©es issues de Google Analytics 4 (GA4)** exportÃ©es depuis BigQuery.

ğŸ“¦ **Input attendu** : des exports GA4 au format **JSON brut** (via BigQuery UI ou Cloud Storage).

Les contrÃ´les suivent les 6 axes du framework de qualitÃ© des donnÃ©es :
- ComplÃ©tude
- ValiditÃ©
- UnicitÃ©
- DisponibilitÃ© (Timeliness)
- CohÃ©rence
- Exactitude

## âš™ï¸ Architecture du Projet
Le projet s'appuie sur :
- **DuckDB** pour le traitement SQL local sur fichiers JSON
- **Python** pour automatiser et encapsuler les analyses
- **Streamlit** pour une visualisation interactive par chapitre (ex: steamlist, validity...)
- **Pandas** pour les dataframes

## ğŸ—‚ï¸ Structure des chapitres
Chaque chapitre du framework correspond Ã  un **module de contrÃ´le** avec sa propre logique mÃ©tier, requÃªtes, et app Streamlit dÃ©diÃ©e.

---

### ğŸ”§ Phase 0 â€“ PrÃ©paration du dataset
- [WIP] PrÃ©parer un data catalogue GA4 Ã  partir des specs officielles Google
- [OK] Identifier le type de dataset via les Ã©vÃ©nements (lead_gen, ecommerce, game...)
- [ ] Conditionner les recommandations en fonction du type de dataset
- [ ] GÃ©rer l'importation et l'affichage des informations basiques de l'extraction dans streamlit
- [ ] GÃ©rer la mise en place de la partie validity dans streamlit avec la librairie urllib.parse
- [ ] DÃ©finir un output pour l'utilisateur et avoir les informations dans un tableau avec une premiÃ¨re analyse

---

### âœ… 1. ComplÃ©tude (Completeness)
VÃ©rifier que les donnÃ©es attendues sont bien prÃ©sentes et disponibles.

ContrÃ´les Ã  implÃ©menter :
- [OK] Lister les dimensions dans la donnÃ©e
- [OK] Lister les Ã©vÃ©nements dans la donnÃ©e
- [OK] Lister les dates dans la donnÃ©e
- [OK] Comparer les Ã©vÃ©nements de la donnÃ©e avec la liste d'Ã©vÃ©nements standard recommandÃ©s par Google
- [ ] Comparer les dimensions par Ã©vÃ©nements standards avec la liste des dimensions recommandÃ©es par Google
- [ ] VÃ©rifier la couverture de la collecte en fonction des dates
- [ ] VÃ©rifier la prÃ©sence de `ga_session_id` (identifiant de session valide)
- [ ] VÃ©rifier la couverture de la collecte des sessions sur la pÃ©riode de l'Ã©chantillon
- [ ] VÃ©rifier la prÃ©sence de `user_pseudo_id` (identifiant utilisateur anonyme)
- [ ] VÃ©rifier la continuitÃ© de la collecte des utilisateurs (`user_pseudo_id`) sur la pÃ©riode de l'Ã©chantillon
- [ ] VÃ©rifier la prÃ©sence de `user_id` (si implÃ©mentÃ© pour les utilisateurs connectÃ©s)
- [ ] VÃ©rifier la couverture de la collecte des utilisateurs (`user_id`) sur la pÃ©riode de l'Ã©chantillon
- [ ] VÃ©rifier la couverture des dimensions par Ã©vÃ©nements (`event_name`, `event_params`)
- [ ] VÃ©rifier la prÃ©sence des Ã©vÃ©nements et des dimensions recommandÃ©es (`event_name`, `event_params`)
- [ ] VÃ©rifier la prÃ©sence des `source/medium/campaign` dans l'URL de la landing page et dans les colonnes spÃ©cifiques (`gclid`, etc.)
- [ ] VÃ©rifier la prÃ©sence des `page_location` dans la donnÃ©e
- [ ] VÃ©rifier la prÃ©sence des Ã©vÃ©nements `session_start` et `first_session` dans la donnÃ©e pour chaque session

---

### ğŸ§ª 2. ValiditÃ© (Validity)
S'assurer que les donnÃ©es ont des valeurs cohÃ©rentes et dans un format attendu.

ContrÃ´les Ã  implÃ©menter :
- [ ] VÃ©rifier que 'user_id' respecte le bon format (UUID, email hashÃ©, ou autre identifiant conforme)
- [ ] VÃ©rifier que `ga_session_id` et `user_pseudo_id` ne contiennent pas de valeurs nulles ou erronÃ©es (`0`, `-1`, `undefined`, `null`)
- [ ] VÃ©rifier que les dimensions clÃ©s ne contiennent pas de valeurs nulles ou erronÃ©es (`0`, `-1`, `undefined`, `null`)
- [ ] VÃ©rifier la validitÃ© des valeurs numÃ©riques (`event_value`, `event_revenue`, `event_currency`)
- [ ] VÃ©rifier la cohÃ©rence des paramÃ¨tres d'URL de `source/medium/campagne` vs `source/medium` (gclid) â†’ taux de matching
- [WIP] VÃ©rifier dans le `page_location` qu'il n'y a pas de paramÃ¨tres d'URL de type PII (email, nom, prÃ©nom...)
- [WIP] VÃ©rifier la prÃ©sence de fragment dans 'page_location' (tableau ou fragment ?)
- [WIP] VÃ©rifier les domains prÃ©sents dans la donnÃ©e (histograme ou tableau ?)
- [WIP] VÃ©rifier que les urls ne sont pas trop longues (tableau avec les url > x char ?)
- [WIP] VÃ©rifier que les urls sont en https => Histograme ?
- [WIP] VÃ©rifier qu'il n'y a pas de doublons d'url
---

### ğŸ§¬ 3. UnicitÃ© (Uniqueness)
Ã‰viter les doublons et collisions dâ€™identifiants.

ContrÃ´les Ã  implÃ©menter :
- [ ] VÃ©rifier lâ€™unicitÃ© des combinaisons `user_pseudo_id + ga_session_id + event_timestamp`
- [ ] VÃ©rifier que les identifiants dâ€™Ã©vÃ©nements (`event_bundle_sequence_id`) ne sont pas dupliquÃ©s dans une mÃªme session
- [ ] VÃ©rifier que les identifiants dâ€™Ã©vÃ©nements (`event_id`) ne sont pas dupliquÃ©s dans une mÃªme session

---

### â±ï¸ 4. DisponibilitÃ© (Timeliness)
VÃ©rifier que la donnÃ©e est collectÃ©e et disponible dans des dÃ©lais acceptables, en respectant les autorisations utilisateurs (RGPD, consentement).

ContrÃ´les Ã  implÃ©menter :
- [ ] VÃ©rifier l'impact du consentement utilisateur sur la collecte des donnÃ©es
- [ ] VÃ©rifier l'impact du CoMo sur la collecte

---

### ğŸ“ˆ 5. CohÃ©rence (Consistency)
Sâ€™assurer que les tendances et structures de la donnÃ©e restent cohÃ©rentes dans le temps.

ContrÃ´les Ã  implÃ©menter :
- [ ] VÃ©rifier la stabilitÃ© du volume dâ€™Ã©vÃ©nements collectÃ©s quotidiennement
- [ ] Comparer les donnÃ©es sur plusieurs jours pour dÃ©tecter dâ€™Ã©ventuelles anomalies ou pertes
- [ ] VÃ©rifier la distribution des valeurs pour chaque dimension critique (`event_name`, `event_params`)

---

### ğŸ¯ 6. Exactitude (Accuracy)
Sâ€™assurer que les valeurs collectÃ©es correspondent bien Ã  la rÃ©alitÃ© des transactions et interactions utilisateur.

ContrÃ´les Ã  implÃ©menter :
- [ ] VÃ©rifier la correspondance entre les revenus GA4 (`purchase_revenue`) et les transactions rÃ©elles du site e-commerce
- [ ] Comparer les donnÃ©es GA4 avec dâ€™autres sources (CRM, backend...)
- [ ] VÃ©rifier que les Ã©vÃ©nements sont bien dÃ©clenchÃ©s au bon moment et avec les bons paramÃ¨tres

---

## ğŸš€ FonctionnalitÃ©s actuelles
- [OK] RequÃªte SQL automatique sur DuckDB
- [OK] Extraction de `event_params`, `event_name`, `page_location`
- [OK] Interface interactive via Streamlit pour `steamlist` (events) et `validity` (params URL)
- [OK] SÃ©paration des fichiers par module (prÃ©paration dâ€™un menu global Streamlit)
- [WIP] Faire une page spÃ©cifique pour l'import de la donnÃ©e
- [] Proposer un jeu de donnÃ©e de test pour l'utilisateur qui n'a pas de donnÃ©e sous la main et favoriser l'onboarding

## ğŸ“¦ Environnement technique
- Python 3.11+
- DuckDB
- Streamlit
- pandas, re, urllib, etc.

---

## ğŸ“ Ã‰tapes du projet
- [OK] DÃ©finir si le projet est faisable via un POC sur quelques critÃ¨res et analyses
- [OK] DÃ©finir comment unnest la donnÃ©e du format JSON
- [ ] DÃ©finir comment unnest la donnÃ©e du format Parquet
- [ ] DÃ©velopper les requÃªtes SQL nÃ©cessaires pour chaque contrÃ´le dans BigQuery
- [ ] Automatiser les tests via un script Python utilisant DuckDB pour le traitement des exports JSON
- [ ] Automatiser les tests via un script Python utilisant DuckDB pour le traitement des exports Parquet
- [ ] GÃ©nÃ©rer un rapport dÃ©taillÃ© sur la qualitÃ© des donnÃ©es GA4
- [WIP] Ajouter en production une page de remerciement

---

## âš ï¸ Limitations actuelles
- Lâ€™export JSON depuis BigQuery UI est limitÃ© Ã  1 Go
- Il faut utiliser Cloud Storage pour rÃ©cupÃ©rer un fichier Parquet propre
- Streamlit Cloud limite lâ€™upload Ã  200 Mo (contournable avec config ou fallback fichier local ou hÃ©bergement de streamlit sur un VPS perso ou utilisation en local)

## ğŸ”— Ressources utiles
- [Matplotlib cheatsheet](https://github.com/matplotlib/cheatsheets)
- Specs GA4 : [Google Analytics 4 documentation](https://support.google.com/analytics/answer/9322688)

---

ğŸ‘¨â€ğŸ’» Auteur : **Sylvain Rouxel**
ğŸ—“ï¸ CrÃ©ation : **2024-12-01**
ğŸ› ï¸ DerniÃ¨re mise Ã  jour : **2025-04-19**
